{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a7cf8e",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08111e86",
   "metadata": {},
   "source": [
    "1. Создать Dataset для загрузки данных (sklearn.datasets.fetch_california_housing)\n",
    "1. Обернуть его в Dataloader\n",
    "1. Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
    "1. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901231f",
   "metadata": {},
   "source": [
    "#### Создать Dataset для загрузки данных (sklearn.datasets.fetch_california_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0659e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms #, datasets\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e505854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = sklearn.datasets.fetch_california_housing(data_home='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ba687d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e187f53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "262dc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset.data\n",
    "target = train_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "63723934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a396595d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1b4c3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f07c231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15480, 8), (5160, 8), (15480,), (5160,))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "30cef260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaliforniaHousing(torch.utils.data.Dataset):\n",
    "    def __init__(self, init_dataset, init_target):\n",
    "        self._base_dataset = init_dataset\n",
    "        self._target = init_target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._base_dataset.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self._base_dataset[idx]).float(), torch.tensor(self._target[idx]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0258965c",
   "metadata": {},
   "source": [
    "#### Обернуть его в Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b49eb8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CaliforniaHousing(X_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=8, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "76fd95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = CaliforniaHousing(X_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(target_dataset, batch_size=5160, shuffle=True, num_workers=8, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69040345",
   "metadata": {},
   "source": [
    "#### Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7274b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.activation==\"relu\":\n",
    "            return F.leaky_relu(x)\n",
    "        if self.activation==\"sigmoid\":\n",
    "            return F.sigmoid(x)\n",
    "        raise RuntimeError\n",
    "        \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
    "        self.fc1 = Perceptron(input_dim, hidden_dim * 2, \"relu\")\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim * 2)\n",
    "        self.dp2 = nn.Dropout(0.5)\n",
    "        self.fc2 = Perceptron(hidden_dim * 2, hidden_dim, \"relu\")\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp3 = nn.Dropout(0.33)\n",
    "        self.fc3 = Perceptron(hidden_dim, 1, \"relu\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.dp3(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148da952",
   "metadata": {},
   "source": [
    "#### Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a0175ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    'Adam': torch.optim.Adam,\n",
    "    'RMSProp': torch.optim.RMSprop,\n",
    "    'SGD': torch.optim.SGD\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f6aabd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : Adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   649] loss: 5.865\n",
      "[1,  1297] loss: 3.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:05<00:45,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   649] loss: 3.026\n",
      "[2,  1297] loss: 3.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:10<00:42,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   649] loss: 2.983\n",
      "[3,  1297] loss: 2.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:15<00:36,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   649] loss: 2.931\n",
      "[4,  1297] loss: 2.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:20<00:30,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   649] loss: 2.988\n",
      "[5,  1297] loss: 2.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:26<00:26,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   649] loss: 2.926\n",
      "[6,  1297] loss: 2.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:32<00:22,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   649] loss: 2.912\n",
      "[7,  1297] loss: 2.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:38<00:16,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   649] loss: 2.900\n",
      "[8,  1297] loss: 2.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:44<00:11,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,   649] loss: 2.861\n",
      "[9,  1297] loss: 2.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:50<00:05,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   649] loss: 2.944\n",
      "[10,  1297] loss: 2.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:56<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f30af361c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f30af361c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.3557902574539185\n",
      "Processing : RMSProp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   649] loss: 3.500\n",
      "[1,  1297] loss: 2.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:04<00:44,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   649] loss: 2.824\n",
      "[2,  1297] loss: 2.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:09<00:39,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   649] loss: 2.801\n",
      "[3,  1297] loss: 2.863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:16<00:38,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   649] loss: 2.975\n",
      "[4,  1297] loss: 2.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:21<00:33,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   649] loss: 2.821\n",
      "[5,  1297] loss: 2.907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:26<00:27,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   649] loss: 2.944\n",
      "[6,  1297] loss: 2.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:32<00:21,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   649] loss: 2.857\n",
      "[7,  1297] loss: 2.861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:37<00:16,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   649] loss: 2.869\n",
      "[8,  1297] loss: 2.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:43<00:11,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,   649] loss: 2.900\n",
      "[9,  1297] loss: 2.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:49<00:05,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   649] loss: 2.864\n",
      "[10,  1297] loss: 2.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:54<00:00,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f30af361c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f30af361c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.352184772491455\n",
      "Processing : SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   649] loss: 3.668\n",
      "[1,  1297] loss: 2.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:04<00:43,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   649] loss: 2.824\n",
      "[2,  1297] loss: 2.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:10<00:40,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   649] loss: 2.843\n",
      "[3,  1297] loss: 2.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:14<00:33,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   649] loss: 2.884\n",
      "[4,  1297] loss: 2.877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:19<00:27,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   649] loss: 2.951\n",
      "[5,  1297] loss: 2.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:24<00:24,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   649] loss: 2.948\n",
      "[6,  1297] loss: 2.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:29<00:19,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   649] loss: 2.897\n",
      "[7,  1297] loss: 2.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:34<00:14,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   649] loss: 2.966\n",
      "[8,  1297] loss: 2.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:38<00:09,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,   649] loss: 2.924\n",
      "[9,  1297] loss: 2.832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:43<00:04,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   649] loss: 2.946\n",
      "[10,  1297] loss: 2.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:48<00:00,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f30af361c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f30af361c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/nevl/anaconda3/envs/learn3/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.3566969633102417\n"
     ]
    }
   ],
   "source": [
    "for key, opt in optimizers.items():\n",
    "    print('Processing : {}'.format(key))\n",
    "    net = FeedForward(8, 64)\n",
    "    if key == 'SGD':\n",
    "        optimizer = opt(net.parameters(), lr=0.01)\n",
    "    else:\n",
    "        optimizer = opt(net.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "    net.train()\n",
    "    \n",
    "    for epoch in tqdm(range(10)):  \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0], data[1]\n",
    "\n",
    "            # обнуляем градиент\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # выводим статистику о процессе обучения\n",
    "            running_loss += loss.item()\n",
    "            if i and i % 648 == 0:    # печатаем каждые 300 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 300))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training is finished!')\n",
    "    \n",
    "    net.eval()\n",
    "    test_iter = iter(test_loader)\n",
    "    for it in test_iter:\n",
    "        inputs, targets = it\n",
    "        pred_target = net(inputs)\n",
    "        target_loss = criterion(pred_target, targets)\n",
    "        print('Test loss: {}'.format(target_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e595bf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Adam: Test loss: 1.3557902574539185\\n    RMSProp: Test loss: 1.352184772491455\\n    SGD: Test loss: 1.3566969633102417\\n'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Adam: Test loss: 1.3557902574539185\n",
    "    RMSProp: Test loss: 1.352184772491455\n",
    "    SGD: Test loss: 1.3566969633102417\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfabcaf",
   "metadata": {},
   "source": [
    "По приведённому выше тесту самым быстрым обучение было при оптимизаторе SGD. Лучшие результаты получены у RMSProp, на вротом месте Adam, SGD на третьем месте. После лекции ожидания были, что Adam вырвется вперёд. Хотя может не достаточное обучение и где-нибудь через 10 эпох Adam победил бы."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
